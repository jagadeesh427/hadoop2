build.sbt

name := "gettingstarted"

version := "0.1"

scalaVersion := "2.10.5"

libraryDependencies ++= Seq("com.typesafe" % "config" % "1.3.1",
  "org.apache.spark" %% "spark-core" % "1.6.2")
  
  code:
  package wordcount

import org.apache.spark.{SparkConf,SparkContext}
import org.apache.hadoop.fs._

object wordcount{
  def main(args: Array[String]) = {
  val conf = new SparkConf().setAppName("word count").setMaster("local")
  val sc = new SparkContext(conf)
  val inputpath = "/Users/jagadeeshyadav/sparkproject/wordcount.txt"
  val output = "/Users/jagadeeshyadav/sparkproject/wordcount3"

  val lines = sc.textFile(inputpath)
  val linesflatmap = lines.flatMap(x => x.split(" "))
  val result = linesflatmap.map(x => (x ,1)).reduceByKey((x,y) => x + y)
  result.saveAsTextFile(output)

  }
}

